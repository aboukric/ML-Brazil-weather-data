# -*- coding: utf-8 -*-
"""task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c74ZpJ2TmN5ynf1owZ0HvUyScZfPJXTA

# Thanks to **Concordia University** for giving me access to **University of Alberta** GPU
"""

# Import libraries.
import numpy as np
import pandas as pd
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
import matplotlib.pyplot as plt
plt.style.use("default")
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import seaborn as sns

"""**Load data one by one to use less RAM**"""

df0 = pd.read_csv('central_west.csv')
#drop any NaN value
df0 = df0.dropna()

# drop the first letter from the station code se we can have nimbers only
# this will be usfull to cahnge it to int
df0["station_code"] = df0["station_code"].str[1:]

df1 = pd.read_csv('north.csv')
df1 = df1.dropna()

df1["station_code"] = df1["station_code"].str[1:]

df2 = pd.read_csv('northeast.csv')
df2 = df2.dropna()

df2["station_code"] = df2["station_code"].str[1:]

df3 = pd.read_csv('south.csv')
df3 = df3.dropna()

df3["station_code"] = df3["station_code"].str[1:]

df4 = pd.read_csv('southeast.csv')
df4 = df4.dropna()

df4["station_code"] = df4["station_code"].str[1:]

#df5 = pd.read_csv('stations.csv')

#df5

"""**creat a single dataframe**"""

df = [df0, df1,df2, df3,df4]

df = pd.concat([df0, df1,df2, df3, df4],ignore_index=True)

#df.info()
df.head()

df.tail()

# change column name to Englist
df.columns = ['index','Date (YYYY-MM-DD)', 'Time (HH:00)', 'Amount of precipitation in millimetres (last hour)', 'Atmospheric pressure at station level (mb)',
             'Maximum air pressure for the last hour (mb)','Minimum air pressure for the last hour (mb)','Solar radiation (KJ/m2)','Air temperature (instant) (°c)',
             'Dew point temperature (instant) (°c)','Maximum temperature for the last hour (°c)','Minimum temperature for the last hour (°c)',
              'Maximum dew point temperature for the last hour (°c)','Minimum dew point temperature for the last hour (°c)','Maximum relative humid temperature for the last hour (%)',
              'Minimum relative humid temperature for the last hour (%)','Relative humid (% instant)','Wind direction (radius degrees (0-360))','Wind gust in metres per second',
              'Wind speed in metres per second','Brazilian geopolitical regions','State (Province)','Station Name (usually city location or nickname)','Station code (INMET number)',
              'Latitude','Longitude','Elevation']
# Show data info.
df.info()

#order the data based on time
df.index.name = None
df = df.sort_values(by=['Date (YYYY-MM-DD)'], ascending=[True])
df.head()

#df.tail()

df.drop(["Time (HH:00)", "Brazilian geopolitical regions", "Station Name (usually city location or nickname)", "State (Province)", "index"], axis=1, inplace=True)

# # Get data from '2017-05-07'. If we have very large RAM we can use the whol data
mask = (df['Date (YYYY-MM-DD)'] > '2017-05-07')
df = df.loc[mask]
df.head()

# choose date as index
df = df.set_index('Date (YYYY-MM-DD)')

df.tail()

#change the Station code to int
df['Station code (INMET number)'] = pd.to_numeric(df['Station code (INMET number)'])

#change -9999 to NaN so we can count them
df = df.replace(-9999.0, np.NaN)

df.tail()

"""## Checking for missing values"""

columnsNanVal = df.isna().sum()
columnsNanVal

# Columns with missing values
colMissVal = df.columns[columnsNanVal != 0].tolist()

# Check the missing values by station
dfCheck = df[colMissVal].isna().groupby(df["Station code (INMET number)"]).sum()

dfCheck

"""## Station 353 has the highest missing values across all columns
so we will analysis **station 353**  
"""

# Select data from station 353.
statio353 = df[df['Station code (INMET number)'] == 353].copy()
statio353.head()

statio353.tail()

statio353.isna().sum()

"""## Cleaning the dataset.

There is some value that can't be negative so we will fill them with 0
"""

# give names to values to be changed
canBeZero = ["Solar radiation (KJ/m2)", "Amount of precipitation in millimetres (last hour)", 'Wind gust in metres per second', 'Wind gust in metres per second']  # Solar radiation (KJ/m2), Amount of precipitation in millimetres (last hour), Wind gust in metres per second, Wind gust in metres per second
OtherColumns = ['Atmospheric pressure at station level (mb)','Maximum air pressure for the last hour (mb)','Minimum air pressure for the last hour (mb)',
                'Air temperature (instant) (°c)','Dew point temperature (instant) (°c)','Maximum temperature for the last hour (°c)',
                'Minimum temperature for the last hour (°c)','Maximum dew point temperature for the last hour (°c)','Minimum dew point temperature for the last hour (°c)',
                'Maximum relative humid temperature for the last hour (%)','Minimum relative humid temperature for the last hour (%)','Relative humid (% instant)',
                'Wind direction (radius degrees (0-360))','Station code (INMET number)']

# Fill missing values that can't be negative with zeros
statio353[canBeZero] = statio353[canBeZero].fillna(0)
statio353.head()

# Interpolate the other missing values
statio353df = statio353.interpolate(method ='linear', limit_direction ='forward', axis=0)
statio353df.tail()

statio353df.isna().sum()

SHAPE = statio353df.shape

# Select rows with all feature columns equal to zero.
feature_columns = ['Atmospheric pressure at station level (mb)','Maximum air pressure for the last hour (mb)','Minimum air pressure for the last hour (mb)',
                'Air temperature (instant) (°c)','Dew point temperature (instant) (°c)','Maximum temperature for the last hour (°c)',
                'Minimum temperature for the last hour (°c)','Maximum dew point temperature for the last hour (°c)','Minimum dew point temperature for the last hour (°c)',
                'Maximum relative humid temperature for the last hour (%)','Minimum relative humid temperature for the last hour (%)','Relative humid (% instant)',
                'Wind direction (radius degrees (0-360))','Station code (INMET number)']
statio353data = statio353df[(statio353df[feature_columns] != 0).any(axis=1)]
statio353data.head()

SHAPE, statio353data.shape

statio353data.info()

"""# Cleaning for Prediction."""

st353PredictDf = statio353data.drop(['Dew point temperature (instant) (°c)','Maximum temperature for the last hour (°c)',
                      'Minimum temperature for the last hour (°c)','Maximum dew point temperature for the last hour (°c)',
                      'Minimum dew point temperature for the last hour (°c)'], axis=1)

st353PredictDf.head()

# import matplotlib.pyplot as plt
import seaborn as sns
 
# #without regression
# sns.pairplot(st353PredictDf, kind="scatter")
# plt.show()

"""**Seaborn Correlation Heatmap**

Thank to 'https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e'
"""

sns.heatmap(st353PredictDf.corr());

plt.figure(figsize=(16, 6))
heatmap = sns.heatmap(st353PredictDf.corr(), vmin=-1, vmax=1, annot=True)
heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);

"""**Training the model, and train test split using pandas**

Thanks to 'https://www.codegrepper.com/code-examples/python/train_test_split+pandas'
"""

#from sklearn.model_selection import train_test_split

X = st353PredictDf.drop(["Air temperature (instant) (°c)"],axis=1).values   # independant features
y = st353PredictDf["Air temperature (instant) (°c)"].values					# dependant variable

# Choose your test size to split between training and testing sets:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

# from sklearn.ensemble import RandomForestClassifier
# from sklearn.datasets import make_classification


# X_train, y_train = make_classification(n_samples=1000,n_features=4,
#                             n_informative=2, n_redundant=0,
#                             random_state=0, shuffle=False)
# clf = RandomForestClassifier(max_depth=2, random_state=0)

# clf.fit(X_train, y_train)

# print(clf.predict([[0, 0, 0, 0]]))

# Define the model
model = RandomForestRegressor(n_estimators=100)
# Train
model.fit(X_train, y_train)

# disply the accuracy of train dataset.
print("the accuracy of train dataset is: ",model.score(X_train, y_train))
print("the accuracy of the test dataset is: ",model.score(X_test, y_test) )